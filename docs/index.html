

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Statistics short-course &mdash; stats-shortcourse 1.0 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="stats-shortcourse 1.0 documentation" href="#"/>
        <link rel="next" title="Getting started" href="getting-started.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="#" class="icon icon-home"> stats-shortcourse
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="getting-started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-concepts.html">Probability Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="combinatorics.html">Combinatorics</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability.html">Probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-distributions.html">Probability distributions</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="paradigms.html">Bayesian Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="statistics-concepts.html">Statistics concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="statistical-inference.html">Statistical inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="regression-classification-metrics.html">Regression, Classification, Evaluation metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="concluding-remarks.html">Data Science Immersive</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="helpful-math.html">Helpful math</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">Works cited</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="#">stats-shortcourse</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="#">Docs</a> &raquo;</li>
      
    <li>Statistics short-course</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/index.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="align-center figure">
<a class="reference internal image-reference" href="_images/galvanize-logo.png"><img alt="galvanize-logo" src="_images/galvanize-logo.png" style="width: 669.55px; height: 167.65px;" /></a>
</div>
<div class="section" id="statistics-short-course">
<h1>Statistics short-course<a class="headerlink" href="#statistics-short-course" title="Permalink to this headline">¶</a></h1>
<div class="section" id="where-are-we-going">
<h2>Where are we going?<a class="headerlink" href="#where-are-we-going" title="Permalink to this headline">¶</a></h2>
<p>Within data science (and perhaps at its core) is the field of <a class="reference external" href="https://en.wikipedia.org/wiki/Machine_learning">Machine learning</a>, which seeks to accomplish two objectives:</p>
<blockquote>
<div><ul class="simple">
<li><strong>Supervised learning</strong> - learn a mapping from inputs <span class="math">\(x\)</span> to outputs <span class="math">\(y\)</span></li>
<li><strong>Unsupervised learning</strong> - given only <span class="math">\(x\)</span>, learn interesting patterns in <span class="math">\(x\)</span></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Machine learning is a type of artificial intelligence that equips a computer
to capture a specific instance of a general class of patterns, and then asks the
computer to determine (for some data) what the actual instance of the pattern is.</p>
<p>This is different than explicitly hardcoding some identified relationship into a
computer as though it was already known beforehand.</p>
<p>Machine learning makes extensive use of <a class="reference external" href="https://en.wikipedia.org/wiki/Linear_algebra">linear algebra</a>&#8212;the branch of
mathematics that works directly with matrices&#8212;in conjunction numerical optimization procedures
in order to identify the patterns present in data.</p>
<p class="last">This is a process called &#8220;model fitting&#8221; which allows a model of generic patterns to be
restricted to a specific example that looks as similar to the data as possible. Once a
machine has such a model representation of the data, then it has &#8220;learned&#8221; the pattern
in the data and can use it as a part of other programatic instructions.</p>
</div>
</div>
<div class="section" id="on-machine-learning-and-statistics">
<h2>On machine learning and statistics<a class="headerlink" href="#on-machine-learning-and-statistics" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://www.quora.com/What-is-the-difference-between-statistics-and-machine-learning">What is the difference between statistics and machine learning?</a></p>
<p>Statistics and Machine Learning represent distinct quantitative analysis methodology
traditions that developed towards distinctive objectives that suited their idiosyncratic access to
different (primarily in terms of computational) problem solving methodologies and philosophies;
however, both disciplines are rooted in the common enterprise of &#8220;data analysis&#8221; and so have
found common ground on which to reconcile and merge methodologies, leading to the
current situation in which the line between the two is increasingly blurry. Nonetheless, some
general statements related to the traditional domains claimed by each discipline can be made:</p>
<p><strong>Statistics</strong></p>
<blockquote>
<div><ul class="simple">
<li>confidence intervals, hypothesis tests, and optimal estimators</li>
<li>characterization of uncertainty in estimation is paramount</li>
<li>results are based on distribution theory and asymptotics</li>
</ul>
</div></blockquote>
<p><strong>Machine Learning</strong></p>
<blockquote>
<div><ul class="simple">
<li>nonparametric and complex models harnessed via regularization</li>
<li>&#8220;out of sample&#8221; performance (i.e., generalizability) is paramount</li>
<li>results leverage empirical and computationally intensive techniques</li>
</ul>
</div></blockquote>
<div class="section" id="what-kind-of-quantitative-methodologies-are-out-there">
<h3>What kind of quantitative methodologies are out there?<a class="headerlink" href="#what-kind-of-quantitative-methodologies-are-out-there" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Descriptive_statistics">Descriptive statistics</a> - mean, median, skewness etc.</li>
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Statistical_inference">Inferential statistics</a>  - hypothesis testing, interval estimation</li>
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Predictive_analytics">Predictive analytics</a> - supervised learning: regression, classification</li>
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Prescriptive_analytics">Prescriptive analytics</a> - unsupervised learning and recommenders</li>
</ul>
</div></blockquote>
<p>But of course, specific applications are rarely restricted to just one of these domains&#8212;these tools are highly synergistically informative and are best leveraged in cohort.</p>
</div>
</div>
<div class="section" id="course-contents">
<h2>Course contents<a class="headerlink" href="#course-contents" title="Permalink to this headline">¶</a></h2>
<div class="section" id="objectives">
<h3>Objectives<a class="headerlink" href="#objectives" title="Permalink to this headline">¶</a></h3>
<p>These materials dig into the basics, introducing the areas of
probability and statistics that are assessed in the statistics and machine learning
interview step of the Galvanize Data Science Immersive admission
process. In addition to the content here, we provide a listing of
resources for further study that review and reinforce these topics.
Mastery of all this material is crucial for forming a strong foundation for statistics,
machine learning, data science, or any other analytical and data-oriented discipline.
And if you are interested in pursuing data science through the
<a class="reference external" href="https://www.galvanize.com/pick-a-locatoin?page=%2Fdata-science">Galvanize Data Science Immersive</a>,
mastery of all this material will help make your Galvanize admission process &#8211; rather than impossible &#8211; a breeze.</p>
<p>We&#8217;ll begin the first day with a gentle introduction to &#8220;counting&#8221; and probability problems.
Then we&#8217;ll continue with an exploration into the (discrete and continuous) distributions most
commonly encountered in statistics. Finally, we&#8217;ll finish with a concept-driven explanation of
the frequentist and Bayesian paradigms (or philosophies) on which today&#8217;s modern statistical analyses are based.</p>
<p>On the second day we&#8217;ll dive a bit further into how to make use of
probability distributions for inference and hypothesis testing. Then
we&#8217;ll introduce regression and classification and explore these
methodologies a little deeper through some example applications.
And finally we&#8217;ll conclude by discussing some of the commonly
used methods for evaluating how useful a model actually is.
After that, if you want to stay around to hear a little bit more about the
Data Science Immersive, you&#8217;re welcome to &#8211; but you don&#8217;t have to.</p>
<p>Day 1</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="getting-started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-concepts.html">Probability Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="combinatorics.html">Combinatorics</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability.html">Probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="probability-distributions.html">Probability distributions</a></li>
</ul>
</div>
<p>Day 2</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="paradigms.html">Bayesian Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="statistics-concepts.html">Statistics concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="statistical-inference.html">Statistical inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="regression-classification-metrics.html">Regression, Classification, Evaluation metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="concluding-remarks.html">Data Science Immersive</a></li>
</ul>
</div>
</div>
</div>
<div class="section" id="resources-for-further-study">
<h2>Resources for further study<a class="headerlink" href="#resources-for-further-study" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><ul class="simple">
<li><a class="reference external" href="https://github.com/zipfian/self-study-resources">Galvanize self study resources</a></li>
<li><a class="reference external" href="http://www.cram.com/flashcards/probability-for-data-science-8215075">Useful flashcards</a></li>
<li><a class="reference external" href="https://www.khanacademy.org/math/statistics-probability">Khan Academy - statistics and probability</a></li>
<li><a class="reference external" href="http://www.dataschool.io/15-hours-of-expert-machine-learning-videos">15 hours of machine learning videos</a></li>
</ul>
</div></blockquote>
<div class="section" id="reference-materials">
<h3>Reference materials<a class="headerlink" href="#reference-materials" title="Permalink to this headline">¶</a></h3>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="helpful-math.html">Helpful math</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">Works cited</a></li>
</ul>
</div>
<p>To view/download the source of these materials visit the GitHub repository.</p>
<blockquote>
<div><ul class="simple">
<li><a class="reference external" href="https://github.com/GalvanizeOpenSource/stats-shortcourse">https://github.com/GalvanizeOpenSource/stats-shortcourse</a></li>
</ul>
</div></blockquote>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="getting-started.html" class="btn btn-neutral float-right" title="Getting started" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Galvanize DSI.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>