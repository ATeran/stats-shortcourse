

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Probability distributions &mdash; stats-shortcourse 1.0 documentation</title>
  

  
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic|Roboto+Slab:400,700|Inconsolata:400,700&subset=latin,cyrillic' rel='stylesheet' type='text/css'>

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="stats-shortcourse 1.0 documentation" href="index.html"/>
        <link rel="next" title="Bayesian Inference" href="paradigms.html"/>
        <link rel="prev" title="Probability" href="probability.html"/> 

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        
          <a href="index.html" class="fa fa-home"> stats-shortcourse</a>
        
        
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
          
          
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting-started.html">Getting started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="getting-started.html#where-are-we-going">Where are we going?</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting-started.html#installing-python">Installing Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting-started.html#installing-an-editor">Installing an editor</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="probability-concepts.html">Probability Concepts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="probability-concepts.html#sets">Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="probability-concepts.html#further-study">Further study</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="combinatorics.html">Combinatorics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="combinatorics.html#factorials">Factorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="combinatorics.html#id1">Combinatorics</a></li>
<li class="toctree-l2"><a class="reference internal" href="combinatorics.html#permutations">Permutations</a></li>
<li class="toctree-l2"><a class="reference internal" href="combinatorics.html#further-study">Further study</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="probability.html">Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="probability.html#formalization">Formalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="probability.html#independence">Independence</a></li>
<li class="toctree-l2"><a class="reference internal" href="probability.html#a-problem">A problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="probability.html#conditional-probability">Conditional probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="probability.html#probability-chain-rule">Probability Chain Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="probability.html#law-of-total-probability">Law of Total Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="probability.html#bayes-rule">Bayes Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="probability.html#bayesian-statistics">Bayesian statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="probability.html#further-resources">Further resources</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Probability distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#properties-of-distributions">Properties of distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rules-for-choosing-a-good-distribution">Rules for choosing a good distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="#essential-distributions">Essential distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#less-essential-distributions">Less essential distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#distributions-are-related">Distributions are related</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="paradigms.html">Bayesian Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="paradigms.html#probability-review">Probability review</a></li>
<li class="toctree-l2"><a class="reference internal" href="paradigms.html#a-tale-of-two-philosophies">A tale of two philosophies</a></li>
<li class="toctree-l2"><a class="reference internal" href="paradigms.html#bayes-theorem">Bayes Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="paradigms.html#the-philosophy-of-bayesian-inference">The Philosophy of Bayesian Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="paradigms.html#but-why">But why?</a></li>
<li class="toctree-l2"><a class="reference internal" href="paradigms.html#the-pieces">The pieces</a></li>
<li class="toctree-l2"><a class="reference internal" href="paradigms.html#further-study">Further study</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="statistics-concepts.html">Statistics concepts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="statistics-concepts.html#pdfs-and-cdfs">PDFs and CDFs</a></li>
<li class="toctree-l2"><a class="reference internal" href="statistics-concepts.html#expectation">Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="statistics-concepts.html#variance">Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="statistics-concepts.html#id1">Correlation</a></li>
<li class="toctree-l2"><a class="reference internal" href="statistics-concepts.html#marginal-distributions">Marginal Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="statistics-concepts.html#further-study">Further study</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="statistical-inference.html">Statistical inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="statistical-inference.html#a-motivating-example">A motivating example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="regression-classification-metrics.html">Regression, Classification, Evaluation metrics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="regression-classification-metrics.html#objectives">Objectives</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression-classification-metrics.html#many-ways-to-say-the-same-thing">Many ways to say the same thing</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression-classification-metrics.html#two-main-types-of-machine-learning-models">Two main types of machine learning models</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression-classification-metrics.html#features">Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression-classification-metrics.html#size-of-data">Size of data</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression-classification-metrics.html#notation">Notation</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression-classification-metrics.html#assumptions">Assumptions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="concluding-remarks.html">Data Science Immersive</a><ul>
<li class="toctree-l2"><a class="reference internal" href="concluding-remarks.html#typical-day">Typical day</a></li>
<li class="toctree-l2"><a class="reference internal" href="concluding-remarks.html#throughout-the-cohort">Throughout the cohort</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="helpful-math.html">Helpful math</a><ul>
<li class="toctree-l2"><a class="reference internal" href="helpful-math.html#algebra">Algebra</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references.html">Works cited</a></li>
</ul>

          
        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">stats-shortcourse</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Probability distributions</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="_sources/probability-distributions.txt" rel="nofollow"> View page source</a>
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document">
            
  <div class="section" id="probability-distributions">
<h1>Probability distributions<a class="headerlink" href="#probability-distributions" title="Permalink to this headline">¶</a></h1>
<p>A probability distribution is a mathematical formalization that describes a particular type of random process. Though a random variable is more general than a probability distribution in that there may not be a known distribution behind a particular variable, often when we think of a random variable we imagine it is being generated by one of these common probability distributions.</p>
<p><a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html">The SciPy docs for statistics</a> is quite useful.</p>
<div class="section" id="properties-of-distributions">
<h2>Properties of distributions<a class="headerlink" href="#properties-of-distributions" title="Permalink to this headline">¶</a></h2>
<p>These are common properties used to characterize a distribution:</p>
<blockquote>
<div><ul class="simple">
<li>Expectation/mean</li>
<li>Variance/standard deviation</li>
<li>Skewness (asymmetry)</li>
<li>Kurtosis (fat tails)</li>
</ul>
</div></blockquote>
</div>
<div class="section" id="rules-for-choosing-a-good-distribution">
<h2>Rules for choosing a good distribution<a class="headerlink" href="#rules-for-choosing-a-good-distribution" title="Permalink to this headline">¶</a></h2>
<div class="section" id="main-questions">
<h3>Main questions<a class="headerlink" href="#main-questions" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li>Are my data discrete or continuous?</li>
<li>Are my data symmetric?</li>
<li>What limits are there on possible values for my data?</li>
</ul>
</div></blockquote>
</div>
<div class="section" id="other-questions-to-keep-in-mind">
<h3>Other questions to keep in mind<a class="headerlink" href="#other-questions-to-keep-in-mind" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li>How likely are extreme values?</li>
<li>Are there missing values?</li>
</ul>
</div></blockquote>
</div>
</div>
<div class="section" id="essential-distributions">
<h2>Essential distributions<a class="headerlink" href="#essential-distributions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="bernoulli">
<h3>Bernoulli:<a class="headerlink" href="#bernoulli" title="Permalink to this headline">¶</a></h3>
<p>A Bernoulli distribution is a discrete probability distribution for a
Bernoulli trial.  The distribution takes the value 1 with success
probability of <span class="math">\(p\)</span> and the value 0 with failure.  Success could
be heads on a coin flip.</p>
<p>PMF = <span class="math">\(P[success] = p\)</span> , <span class="math">\(P[failure] = 1-p\)</span></p>
<p>Mean: <span class="math">\(E[x] = p\)</span></p>
<p>Variance: <span class="math">\(Var(x) = p(1-p)\)</span></p>
<p>(<a class="reference external" href=".//bernoulli-distn.py">Source code</a>, <a class="reference external" href=".//bernoulli-distn.png">png</a>, <a class="reference external" href=".//bernoulli-distn.hires.png">hires.png</a>, <a class="reference external" href=".//bernoulli-distn.pdf">pdf</a>)</p>
<div class="figure">
<img alt="_images/bernoulli-distn.png" src="_images/bernoulli-distn.png" />
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Lets say that I polled all first graders in the state of
colorado and asked the question do you like/dislike your teacher.
The answers are discrete values and the distribution of those
answers could be modelled with a Bernoulli.</p>
<p class="last">Can you think of another example?</p>
</div>
<p>See this <a class="reference external" href="https://www.khanacademy.org/math/statistics-probability/sampling-distributions-library/sample-proportions/v/mean-and-variance-of-bernoulli-distribution-example">khan academy video on the Bernoulli to get a better intuition</a></p>
</div>
<div class="section" id="binomial">
<h3>Binomial:<a class="headerlink" href="#binomial" title="Permalink to this headline">¶</a></h3>
<p>The Binomial distribution gives the discrete probability distribution
of obtaining exactly <cite>k</cite> successes out of <cite>n</cite> trials</p>
<p>PMF: <span class="math">\(P[X=k] = {n \choose k}p^k(1-p)^{n-k}, \forall k \in \{0, 1,..., n\}\)</span></p>
<p>Mean: <span class="math">\(np\)</span></p>
<p>Var: <span class="math">\(np(1-p)\)</span></p>
<p>(<a class="reference external" href=".//binomial-distn.py">Source code</a>, <a class="reference external" href=".//binomial-distn.png">png</a>, <a class="reference external" href=".//binomial-distn.hires.png">hires.png</a>, <a class="reference external" href=".//binomial-distn.pdf">pdf</a>)</p>
<div class="figure">
<img alt="_images/binomial-distn.png" src="_images/binomial-distn.png" />
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The number of heads that come from flipping a coin 10 times can be modeled with a binomial</p>
<p>Can you think of another example that might be modeled by a binomial?</p>
<p class="last">See this <a class="reference external" href="https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library/binomial-random-variables/v/binomial-distribution">khan academy video on the binomial distribution to get a better intuition</a></p>
</div>
</div>
<div class="section" id="poisson">
<h3>Poisson<a class="headerlink" href="#poisson" title="Permalink to this headline">¶</a></h3>
<p>If a mean of an event happening per unit time is observed and you need the probability of <cite>n</cite> events happening</p>
<p>PMF: <span class="math">\(P[X=k] = \frac{\lambda^k e^{-\lambda}}{k!},\forall k \in \{0,1,2,...\}\)</span></p>
<p>Mean: <span class="math">\(\lambda\)</span></p>
<p>Variance: <span class="math">\(\lambda\)</span></p>
<p>(<a class="reference external" href=".//poisson-distn.py">Source code</a>, <a class="reference external" href=".//poisson-distn.png">png</a>, <a class="reference external" href=".//poisson-distn.hires.png">hires.png</a>, <a class="reference external" href=".//poisson-distn.pdf">pdf</a>)</p>
<div class="figure">
<img alt="_images/poisson-distn.png" src="_images/poisson-distn.png" />
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The probability that one,two,..., <span class="math">\(n\)</span> uber cars pass in front of my building in an hour</p>
<p class="last">Can you think of another example?</p>
</div>
<p>See this <a class="reference external" href="https://www.youtube.com/watch?v=3z-M6sbGIZ0">How does the binomial relate to the poisson (khan academy) video</a></p>
<p>Then check out the <a class="reference external" href="https://www.youtube.com/watch?v=Jkr4FSrNEVY">example on the poisson distribution (khan academy) video</a></p>
<p>Some <a class="reference external" href="https://www.umass.edu/wsp/resources/poisson">poisson examples are discussed here</a></p>
</div>
<div class="section" id="uniform">
<h3>Uniform<a class="headerlink" href="#uniform" title="Permalink to this headline">¶</a></h3>
<p>PDF: <span class="math">\(f(x) = \frac{1}{b-a}, \forall x\in[a, b]\)</span>,  0 otherwise</p>
<p>MEAN: <span class="math">\(\frac{a+b}{2}\)</span></p>
<p>VARIANCE: <span class="math">\(\frac{(b-a)^2}{2}\)</span></p>
</div>
<div class="section" id="normal-aka-gaussian">
<h3>Normal aka Gaussian<a class="headerlink" href="#normal-aka-gaussian" title="Permalink to this headline">¶</a></h3>
<p>The Gaussian is the most widely used distribution for continuous
variables. The distribution is governed by the mean <span class="math">\(\mu\)</span> and variance <span class="math">\(\sigma^2\)</span>.</p>
<p>SUPPORT <span class="math">\(x \in (-\inf, \inf)\)</span></p>
<p>PDF: <span class="math">\(\frac{1}{\sqrt{2\pi\sigma^2}}exp(-\frac{(x - \mu)^2}{2\sigma^2})\)</span></p>
<p>MEAN: <span class="math">\(\mu\)</span></p>
<p>VARIANCE: <span class="math">\(\sigma^2\)</span></p>
<p>The inverse of the variance is known as the <strong>precision</strong> (<span class="math">\(\tau = 1/\sigma^{2}\)</span>).</p>
<p>(<a class="reference external" href=".//gaussian-distn.py">Source code</a>, <a class="reference external" href=".//gaussian-distn.png">png</a>, <a class="reference external" href=".//gaussian-distn.hires.png">hires.png</a>, <a class="reference external" href=".//gaussian-distn.pdf">pdf</a>)</p>
<div class="figure">
<img alt="_images/gaussian-distn.png" src="_images/gaussian-distn.png" />
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">test scores, IQs, heights, finishing times from the boston marathons (almost)</p>
</div>
<p><a class="reference external" href="https://www.khanacademy.org/math/statistics-probability/modeling-distributions-of-data/normal-distributions-library/v/introduction-to-the-normal-distribution">Khan academy intro</a></p>
<p>This is a really important distribution because it appears over and over in nature.  It is extremely useful in statistical inference and it is a key component of <a class="reference external" href="https://en.wikipedia.org/wiki/Central_limit_theorem">the central limit theorem</a>.</p>
</div>
</div>
<div class="section" id="less-essential-distributions">
<h2>Less essential distributions<a class="headerlink" href="#less-essential-distributions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="geometric">
<h3>Geometric<a class="headerlink" href="#geometric" title="Permalink to this headline">¶</a></h3>
<p>The probability of some number (<cite>X</cite>) of Bernoulli trials needed to get one success.  It also refers to probability of (<cite>X-1</cite>) failures before the first success.</p>
<p>PMF: <span class="math">\(P[X=k] = p (1-p)^{k-1}, \forall k \in \{0, 1,...\}\)</span></p>
<p>Mean: <span class="math">\(\frac{1}{p}\)</span></p>
<p>Variance: :<cite>frac{1-p}{p^2}</cite></p>
</div>
<div class="section" id="hypergeometric">
<h3>Hypergeometric<a class="headerlink" href="#hypergeometric" title="Permalink to this headline">¶</a></h3>
<p>Hypergeometric distribution is a discrete probability distribution
that describes the probability of <cite>k</cite> successes in <cite>n</cite> draws, without
replacement.</p>
<p>The hypergeometric test uses the hypergeometric distribution to
calculate the statistical significance of having drawn a specific k
successes n total draws</p>
<p>Think of an urn with two types of marbles, red ones and green
ones. Define drawing a green marble as a success and drawing a red
marble as a failure (analogous to the binomial distribution).</p>
<p>Did I draw the <strong>expected</strong> number of green marbles?</p>
<p>The data are not accurately modeled by the binomial distribution,
because the probability of success on each trial is not the same.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Think Texas Hold em</p>
</div>
</div>
<div class="section" id="exponential">
<h3>Exponential<a class="headerlink" href="#exponential" title="Permalink to this headline">¶</a></h3>
<p>A good way to model the time between events for a poisson
process.  It is a particular case of the gamma distribution.
It is governed by a rate parameter <span class="math">\(\lambda\)</span>.</p>
<p>SUPPORT: <span class="math">\(x \in (0, \inf)\)</span>.</p>
<p>PDF: <span class="math">\(\lambda e^{-\lambda x}\)</span></p>
<p>MEAN: <span class="math">\(\frac{1}{\lambda}\)</span></p>
<p>VARIANCE: <span class="math">\(\frac{1}{\lambda^2}\)</span></p>
<p>(<a class="reference external" href=".//exponential-distn.py">Source code</a>, <a class="reference external" href=".//exponential-distn.png">png</a>, <a class="reference external" href=".//exponential-distn.hires.png">hires.png</a>, <a class="reference external" href=".//exponential-distn.pdf">pdf</a>)</p>
<div class="figure">
<img alt="_images/exponential-distn.png" src="_images/exponential-distn.png" />
</div>
</div>
</div>
<div class="section" id="distributions-are-related">
<h2>Distributions are related<a class="headerlink" href="#distributions-are-related" title="Permalink to this headline">¶</a></h2>
<p>There are many more distributions than the ones mentioned above.  Here is an illustration from <em>Casella and Berger</em> that does a pretty good job making that point.</p>
<div class="align-center figure">
<a class="reference internal image-reference" href="_images/statistical-inference-distns.jpg"><img alt="distns" src="_images/statistical-inference-distns.jpg" style="width: 1029.35px; height: 1235.85px;" /></a>
</div>
</div>
</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="paradigms.html" class="btn btn-neutral float-right" title="Bayesian Inference">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="probability.html" class="btn btn-neutral" title="Probability"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Galvanize DSI.
    </p>
  </div>

  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
</footer>
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>